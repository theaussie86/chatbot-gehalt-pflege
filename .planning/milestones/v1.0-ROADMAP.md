# Milestone v1.0: Document Pipeline

**Status:** SHIPPED 2026-01-25
**Phases:** 1-6
**Total Plans:** 14

## Overview

This milestone transformed the document pipeline from a broken state (chunks not being created) to a production-ready system where admins can upload, process, and search documents reliably. Documents uploaded by admins now reliably become searchable context for the chatbot.

## Phases

### Phase 1: Database & Storage Foundation

**Goal:** Database schema and storage bucket are correctly configured with secure RLS policies that allow the processing pipeline to insert chunks.

**Depends on:** None (foundation phase)
**Plans:** 1 plan

Plans:
- [x] 01-01: Fix RLS policies, add error_details column, verify cascade delete

**Details:**
- Fixed P0-blocking RLS policy preventing edge function from inserting chunks
- Added error_details JSONB column for structured error storage
- Verified cascade delete configuration works correctly
- Service role policy uses `auth.jwt()->>'role' = 'service_role'` check

### Phase 2: Atomic File Operations

**Goal:** Admins can upload, delete, and download documents with compensating transactions that prevent orphaned files or database records.

**Depends on:** Phase 1
**Plans:** 3 plans

Plans:
- [x] 02-01: Upload service with drag-drop UI, validation, and rollback visibility
- [x] 02-02: Atomic delete (DB-first) and 5-minute signed URL downloads
- [x] 02-03: Human verification of complete file operations workflow

**Details:**
- PDF, TXT, and spreadsheet upload with size/type validation (50MB limit)
- Direct browser upload for files >1MB (bypasses Next.js body size limit)
- DB-first delete pattern prevents orphaned records
- 5-minute signed URL expiry for downloads

### Phase 3: Status & Error Tracking

**Goal:** Documents visibly reflect their pipeline state, and admins can understand what went wrong when processing fails.

**Depends on:** Phase 2
**Plans:** 3 plans

Plans:
- [x] 03-01: Status badges with icons and filter chips with counts
- [x] 03-02: Document details side panel and real-time status updates
- [x] 03-03: Checkbox selection, bulk delete, and human verification

**Details:**
- Status badges: pending (slate), processing (sky), embedded (emerald), error (rose)
- Real-time updates via Supabase postgres_changes subscription
- Bulk delete with per-document atomicity and confirmation dialogs
- Error details displayed in side panel with full context

### Phase 4: Durable Document Processing

**Goal:** Inngest pipeline successfully creates chunks with embeddings in document_chunks table when triggered by document upload.

**Depends on:** Phase 1, Phase 2
**Plans:** 4 plans

Plans:
- [x] 04-01: Fix Blob MIME type, error handling, request body parsing
- [x] 04-02: Defensive embedding parsing and Promise.allSettled batch processing
- [x] 04-03: Improved chunking and file type handling
- [x] 04-04: Deploy and verify end-to-end processing

**Details:**
- Architecture migrated from Edge Function to Inngest for durable execution
- Automatic retries (3 attempts per step) with built-in observability
- 768-dimensional embeddings via text-embedding-004
- Scanned PDFs process successfully via Gemini OCR
- 2000 char chunks with 100 char overlap

### Phase 5: Error Recovery

**Goal:** Admins can recover from processing failures by reprocessing documents without re-uploading.

**Depends on:** Phase 3, Phase 4
**Plans:** 1 plan

Plans:
- [x] 05-01: Complete reprocess workflow with error history

**Details:**
- Reprocess button on error/embedded documents
- Chunk cleanup before reprocessing ensures clean slate
- Error history preserved as array across retry attempts
- Backward compatibility for legacy single-error format

### Phase 6: RAG Integration

**Goal:** Chatbot uses embedded documents to provide context-aware answers about German nursing tariffs.

**Depends on:** Phase 4
**Plans:** 2 plans

Plans:
- [x] 06-01: Metadata-aware search (SQL function + VectorstoreService enhancement)
- [x] 06-02: Chat route integration with citations + cache invalidation

**Details:**
- queryWithMetadata() returns chunks with document filenames
- 0.75 similarity threshold filters low-quality matches
- Numbered citation format: [Quelle 1: filename.pdf]
- Cache invalidation on delete/reprocess/bulk-delete

---

## Milestone Summary

**Key Decisions:**

| Decision | Rationale | Phase |
|----------|-----------|-------|
| Inngest over Edge Functions | Better durability, retries, observability | 4 |
| DB-first delete pattern | Prevents orphaned DB records on storage failure | 2 |
| Service role RLS via JWT claim | Edge function has NULL auth.uid() | 1 |
| Promise.allSettled for batches | Partial failure tolerance | 4 |
| Error history as array | Preserve retry attempts for debugging | 5 |
| 0.75 similarity threshold | Filter low-quality RAG matches | 6 |

**Issues Resolved:**

- P0: RLS policies checking auth.uid() failed for service role (NULL uid)
- P0: Embedding API response structure assumptions caused failures
- P0: Blob MIME type property mismatch (.type vs .mime_type)
- Gemini file upload response structure (file.name not file.file.name)
- Realtime subscription not working (table not in supabase_realtime publication)
- Cross-origin download issues (blob fetch solution)

**Issues Deferred to v2:**

- Automatic retry with exponential backoff (handled by Inngest)
- Progress percentage tracking during processing
- Orphan cleanup scheduler
- Advanced citation formats (page numbers, sections)

**Technical Debt Incurred:**

None - all phases completed without deferred items.

---

_For current project status, see .planning/PROJECT.md_
